calibration_set:

  # =====================================================
  # GENERAL REASONING: Best All-Around Calibration Dataset
  # Optimized for quantizing reasoning models while
  # preserving broad general capabilities
  # =====================================================
  #
  # Design Philosophy:
  # - Reasoning-intensive categories make up ~57% of data
  #   to ensure proper calibration of chain-of-thought,
  #   step-by-step reasoning, and logical inference paths
  # - Remaining ~43% covers breadth across writing, law,
  #   medicine, finance, news, etc. to prevent capability
  #   collapse during quantization
  # - Includes explicit reasoning traces (OpenThoughts)
  #   for models trained with think/reflect patterns
  # =====================================================

  max_seq_length: 2048
  shuffle: true
  seed: 42

  # =====================================================
  # Category Summary (Total: 512 samples)
  # =====================================================
  # REASONING CORE (~57%):
  #   Mathematical Reasoning    (82 samples - 16.0%)
  #   Coding & Programming      (70 samples - 13.7%)
  #   Reasoning Traces (CoT)    (60 samples - 11.7%)
  #   Scientific Reasoning      (50 samples -  9.8%)
  #   Logical & Commonsense     (28 samples -  5.5%)
  #
  # GENERAL BREADTH (~43%):
  #   General Chat & Instruct   (40 samples -  7.8%)
  #   Tool Use & Function Call  (25 samples -  4.9%)
  #   Creative Writing          (25 samples -  4.9%)
  #   History & Humanities      (22 samples -  4.3%)
  #   Finance & Business        (20 samples -  3.9%)
  #   Medical & Health          (20 samples -  3.9%)
  #   News & Analysis           (19 samples -  3.7%)
  #   Law & Ethics              (15 samples -  2.9%)
  #   Roleplay & Character      (14 samples -  2.7%)
  #   Multilingual              (12 samples -  2.3%)
  #   General Knowledge         (10 samples -  2.0%)
  # =====================================================

  datasets:

    # ================================================
    # Mathematical Reasoning — 82 samples (16.0%)
    # Competition math, proofs, word problems with
    # chain-of-thought solutions and reasoning traces
    # ================================================

    # DeepSeek-R1 reasoning traces for math (long CoT)
    - dataset: nvidia/OpenMathReasoning
      split: cot
      columns: [problem, generated_solution]
      formatter: prompt_answer
      num_samples: 30
      streaming: true

    # Competition math with step-by-step CoT solutions
    - dataset: AI-MO/NuminaMath-CoT
      split: train
      columns: [problem, solution]
      formatter: prompt_answer
      num_samples: 22

    # High-quality math instruction pairs
    - dataset: nvidia/OpenMathInstruct-2
      split: train
      columns: [problem, generated_solution]
      formatter: prompt_answer
      num_samples: 15
      streaming: true

    # Algorithmic / Project Euler problems
    - dataset: MathArena/project_euler
      split: train
      columns: [problem]
      formatter: raw_text
      num_samples: 15


    # ================================================
    # Coding & Programming — 70 samples (13.7%)
    # Diverse programming challenges, competitive
    # coding, and software engineering reasoning
    # ================================================

    # Broad code instruction data
    - dataset: nvidia/OpenCodeInstruct
      split: train
      columns: [input, output]
      formatter: prompt_answer
      num_samples: 20
      streaming: true

    # Hermes-quality code + reasoning blend
    - dataset: rombodawg/code_bagel_hermes-2.5
      split: train
      columns: [input, output]
      formatter: prompt_answer
      num_samples: 20

    # Interactive coding challenges
    - dataset: CSJianYang/CodeArena
      split: test
      columns: [messages]
      formatter: chat_completion
      num_samples: 15

    # Code reasoning and algebra
    - dataset: sr5434/CodegebraGPT_data
      subset: 100k-text
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 15


    # ================================================
    # Reasoning Traces (Chain-of-Thought) — 60 samples (11.7%)
    # Explicit long-form reasoning with think/reflect
    # patterns — critical for reasoning model calibration
    # ================================================

    # QwQ-32B reasoning traces (math, code, general)
    # Contains <|begin_of_thought|>...<|end_of_thought|> patterns
    - dataset: open-thoughts/OpenThoughts-114k
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 35

    # STEM reasoning with diverse instruction types
    - dataset: garage-bAInd/Open-Platypus
      split: train
      columns: [instruction, output]
      formatter: prompt_answer
      num_samples: 15

    # High-quality helpful responses with reasoning
    - dataset: nvidia/HelpSteer
      split: train
      columns: [prompt, response]
      formatter: prompt_answer
      num_samples: 10


    # ================================================
    # Scientific Reasoning — 50 samples (9.8%)
    # Physics, Chemistry, Biology, and general science
    # with detailed explanations and derivations
    # ================================================

    # Multi-domain science reasoning
    - dataset: nvidia/OpenScienceReasoning-2
      split: train
      columns: [input, output]
      formatter: prompt_answer
      num_samples: 15
      streaming: true

    # Physics problems with detailed solutions
    - dataset: camel-ai/physics
      split: train
      columns: [message_1, message_2]
      formatter: prompt_answer
      num_samples: 10

    # Chemistry problems with detailed solutions
    - dataset: camel-ai/chemistry
      split: train
      columns: [message_1, message_2]
      formatter: prompt_answer
      num_samples: 10

    # Biology problems with detailed solutions
    - dataset: camel-ai/biology
      split: train
      columns: [message_1, message_2]
      formatter: prompt_answer
      num_samples: 8

    # Nemotron science reasoning subset
    - dataset: nvidia/Llama-Nemotron-Post-Training-Dataset
      split: science
      columns: [input]
      formatter: chat_completion
      num_samples: 7
      streaming: true


    # ================================================
    # Logical & Commonsense Reasoning — 28 samples (5.5%)
    # Physical intuition, theory of mind, and
    # commonsense inference chains
    # ================================================

    # Physical world reasoning (gravity, forces, etc.)
    - dataset: PJMixers/grimulkan_physical-reasoning-ShareGPT
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 14

    # Theory of mind and social reasoning
    - dataset: PJMixers/grimulkan_theory-of-mind-ShareGPT
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 14


    # ================================================
    # Tool Use & Function Calling — 25 samples (4.9%)
    # Reasoning about when and how to use tools,
    # structured outputs, and function calling
    # ================================================

    # Reasoning-based tool use conversations
    - dataset: interstellarninja/hermes_reasoning_tool_use
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 25


    # ================================================
    # General Chat & Instructions — 40 samples (7.8%)
    # Baseline conversational ability, instruction
    # following, and general helpfulness
    # ================================================

    # General calibration data (Neural Magic)
    - dataset: neuralmagic/calibration
      subset: LLM
      split: train
      columns: [messages]
      formatter: chat_completion
      num_samples: 10

    # Diverse conversation topics
    - dataset: HuggingFaceH4/ultrachat_200k
      split: train_sft
      columns: [messages]
      formatter: chat_completion
      num_samples: 12

    # Instruction-response pairs across categories
    - dataset: databricks/databricks-dolly-15k
      split: train
      columns: [instruction, response]
      formatter: prompt_answer
      num_samples: 10

    # Human-written, high-quality instructions
    - dataset: HuggingFaceH4/no_robots
      split: train
      columns: [messages]
      formatter: chat_completion
      num_samples: 8


    # ================================================
    # Creative Writing — 25 samples (4.9%)
    # Narrative fiction, prose style, and creative
    # voice — prevents quality loss in generation
    # ================================================

    # Premium Claude-quality writing prompts
    - dataset: Gryphe/Opus-WritingPrompts
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 10

    # Community writing prompts — diverse styles
    - dataset: euclaise/writingprompts
      split: train
      columns: [prompt, story]
      formatter: prompt_answer
      num_samples: 8

    # Claude writing — rich descriptive prose
    - dataset: anthracite-org/nopm_claude_writing_fixed
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 7


    # ================================================
    # History & Humanities — 22 samples (4.3%)
    # Philosophy, historical analysis, and humanistic
    # reasoning — exercises different reasoning patterns
    # ================================================

    # Stanford Encyclopedia of Philosophy Q&A
    - dataset: ruggsea/stanford-encyclopedia-of-philosophy_instruct
      split: train
      columns: [question, answer]
      formatter: prompt_answer
      num_samples: 8

    # Philosophy StackExchange discussions
    - dataset: mlfoundations-dev/stackexchange_philosophy
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 7

    # Socratic dialogue — dialectical reasoning
    - dataset: FreedomIntelligence/SocraticChat
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 7


    # ================================================
    # Finance & Business — 20 samples (3.9%)
    # Financial reasoning, business analysis,
    # and quantitative thinking
    # ================================================

    # Finance instruction-following
    - dataset: gbharti/finance-alpaca
      split: train
      columns: [instruction, output]
      formatter: prompt_answer
      num_samples: 8

    # Business knowledge Q&A
    - dataset: theoldmandthesea/17k_business_book
      split: train
      columns: [question, answer]
      formatter: prompt_answer
      num_samples: 8

    # Business and professional prompts
    - dataset: fka/awesome-chatgpt-prompts
      split: train
      columns: [prompt]
      formatter: raw_text
      num_samples: 4


    # ================================================
    # Medical & Health — 20 samples (3.9%)
    # Medical reasoning and scientific literature
    # comprehension — tests analytical capabilities
    # ================================================

    # Medical reasoning with GPT-OSS-120B quality
    - dataset: OpenMed/Medical-Reasoning-SFT-GPT-OSS-120B
      split: train
      columns: [messages]
      formatter: chat_completion
      num_samples: 10
      streaming: true

    # PubMed article summarization
    - dataset: ccdv/pubmed-summarization
      subset: section
      split: train
      columns: [article]
      formatter: raw_text
      num_samples: 10
      streaming: true


    # ================================================
    # News & Analysis — 19 samples (3.7%)
    # Analytical writing, essays, and nonfiction
    # comprehension — exercises summarization reasoning
    # ================================================

    # Medium articles — diverse analytical writing
    - dataset: fabiochiu/medium-articles
      split: train
      columns: [content, title]
      formatter: raw_text
      num_samples: 10
      streaming: true

    # Paul Graham essays — analytical reasoning
    - dataset: sgoel9/paul_graham_essays
      split: train
      columns: [text, title]
      formatter: raw_text
      num_samples: 9


    # ================================================
    # Law & Ethics — 15 samples (2.9%)
    # Legal reasoning and ethical analysis —
    # structured argumentation patterns
    # ================================================

    # Legal instruction-following and reasoning
    - dataset: Alignment-Lab-AI/Lawyer-Instruct
      split: train
      columns: [instruction, output]
      formatter: prompt_answer
      num_samples: 15


    # ================================================
    # Roleplay & Character — 14 samples (2.7%)
    # Character voice and persona — prevents
    # creative generation capability loss
    # ================================================

    # High-quality filtered RP interactions
    - dataset: anthracite-org/stheno-filtered-v1.1
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 8

    # Classic fiction for literary grounding
    - dataset: sam-paech/gutenberg3-generalfiction-scifi-fantasy-romance-adventure-dpo
      split: train
      columns: [chosen]
      formatter: chat_completion
      num_samples: 6


    # ================================================
    # Multilingual — 12 samples (2.3%)
    # Cross-language reasoning breadth
    # ================================================

    # Multilingual thinking and reasoning
    - dataset: HuggingFaceH4/Multilingual-Thinking
      split: train
      columns: [user]
      formatter: raw_text
      num_samples: 12


    # ================================================
    # General Knowledge — 10 samples (2.0%)
    # Pop culture, survival skills, and miscellaneous
    # knowledge to round out coverage
    # ================================================

    # Pop culture and tropes analysis
    - dataset: KaraKaraWitch/TvTroper-2025
      split: train
      columns: [article]
      formatter: raw_text
      num_samples: 5

    # Specialized practical knowledge
    - dataset: AquaV/US-Army-Survival-Sharegpt
      split: train
      columns: [conversations]
      formatter: sharegpt
      num_samples: 5
