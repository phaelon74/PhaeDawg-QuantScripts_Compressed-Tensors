[?2004l[?2004h(venv) phaedawg@d011sd01:~/nvidia-opt/PhaeDawg-QuantScripts_Compressed-Tensors/Nvidia-Model_OPT$ cd Nvidia-Model_OPT/lear[Kgit pull[3Pcd ..python3 quantize_nvfp4.py     --input_model /media/fmodels/meta-llama/Llama-3.1-8B-Instruct/     --output_model /media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4     --dataset_yaml Datasets/Dataset_Example.yaml
[?2004l/home/phaedawg/nvidia-opt/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:1007: UserWarning: Can't initialize NVML
  raw_cnt = _raw_device_count_nvml()

======================================================================
NVFP4 Quantization with NVIDIA Model Optimizer
======================================================================
Input model:  /media/fmodels/meta-llama/Llama-3.1-8B-Instruct/
Output model: /media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4
Dataset YAML: Datasets/Dataset_Example.yaml
Mode:         W4A16 (FP4 weights + FP16 activations)
======================================================================

CUDA Device: NVIDIA RTX PRO 6000 Blackwell Workstation Edition
CUDA Memory: 102.0 GB

Loading tokenizer...
Tokenizer loaded: vocab_size=128000

Loading model...
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|                                                                                                                                                                                                                                            | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                                           | 1/4 [00:00<00:01,  2.40it/s]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                  | 2/4 [00:00<00:00,  2.11it/s]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                         | 3/4 [00:01<00:00,  2.15it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.71it/s]
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
Model loaded: llama
Parameters: 8.03B
GPU Memory Used: 16.06 GB

Preparing calibration dataset...

======================================================================
Loading calibration dataset configuration...
======================================================================
Max samples: 512
Max sequence length: 2048
Random seed: 42

Loading 21 datasets...
  - opus_writing_prompts: 40 samples (weight=7.84%)
  - community_writing_prompts: 35 samples (weight=6.86%)
  - gutenberg_fiction: 25 samples (weight=4.90%)
  - stheno_roleplay: 50 samples (weight=9.80%)
  - kalo_opus_instruct: 40 samples (weight=7.84%)
  - opus_writing_rp: 10 samples (weight=1.96%)
  - ultrachat: 40 samples (weight=7.84%)
Loading dataset shards:   0%|                                                                                                                                                                                                                                              | 0/19 [00:00<?, ?it/s]
Loading dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 2356.21it/s]
  - persona_chat: 30 samples (weight=5.88%)
  - ultrachat_200k: 20 samples (weight=3.92%)
  - claude_writing: 30 samples (weight=5.88%)
  - prosemaxx_adventure: 30 samples (weight=5.88%)
  - gpt4o_writing: 30 samples (weight=5.88%)
  - writing_aug: 20 samples (weight=3.92%)
  - helpsteer: 20 samples (weight=3.92%)
  - open_platypus: 15 samples (weight=2.94%)
  - openmath: 10 samples (weight=1.96%)
Resolving data files:   0%|                                                                                                                                                                                                                                                | 0/32 [00:00<?, ?it/s]
Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 25257.38it/s]
Resolving data files:   0%|                                                                                                                                                                                                                                                | 0/32 [00:00<?, ?it/s]
Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 28648.39it/s]
Map:   0%|                                                                                                                                                                                                                                                          | 0/10 [00:00<?, ? examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 3148.40 examples/s]
Filter:   0%|                                                                                                                                                                                                                                                       | 0/10 [00:00<?, ? examples/s]
Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 3459.79 examples/s]
  - dolly: 15 samples (weight=2.94%)
  - poetry: 10 samples (weight=1.96%)
Repo card metadata block was not found. Setting CardData to empty.
  - quotes: 10 samples (weight=1.96%)
  - code_instructions: 20 samples (weight=3.92%)
  - multilingual: 10 samples (weight=1.96%)

Total samples loaded: 440
Tokenizing samples...
Final dataset size: 374 samples
======================================================================


Configuring NVFP4 quantization...
Available ModelOpt configs: ['FP8_2D_BLOCKWISE_WEIGHT_ONLY_CFG', 'FP8_AFFINE_KV_CFG', 'FP8_DEFAULT_CFG', 'FP8_KV_CFG', 'FP8_PER_CHANNEL_PER_TOKEN_CFG', 'INT4_AWQ_CFG', 'INT4_BLOCKWISE_WEIGHT_ONLY_CFG', 'INT8_DEFAULT_CFG', 'INT8_SMOOTHQUANT_CFG', 'INT8_WEIGHT_ONLY_CFG', 'MXFP4_DEFAULT_CFG', 'MXFP4_MLP_WEIGHT_ONLY_CFG', 'MXFP6_DEFAULT_CFG', 'MXFP8_DEFAULT_CFG', 'MXINT8_DEFAULT_CFG', 'NVFP4_AFFINE_KV_CFG', 'NVFP4_AWQ_CLIP_CFG', 'NVFP4_AWQ_FULL_CFG', 'NVFP4_AWQ_LITE_CFG', 'NVFP4_DEFAULT_CFG', 'NVFP4_KV_CFG', 'NVFP4_KV_ROTATE_CFG', 'NVFP4_MLP_ONLY_CFG', 'NVFP4_MLP_WEIGHT_ONLY_CFG', 'NVFP4_SVDQUANT_DEFAULT_CFG', 'W4A8_AWQ_BETA_CFG', 'W4A8_MXFP4_FP8_CFG', 'W4A8_NVFP4_FP8_CFG']
Using predefined config: mtq.NVFP4_DEFAULT_CFG
Using W4A16 configuration (FP4 weights + FP16 activations)

======================================================================
Running calibration and quantization...
======================================================================

Registered <class 'transformers.models.llama.modeling_llama.LlamaAttention'> to _QuantAttention for KV Cache quantization
Inserted 771 quantizers
  Calibration progress: 50/374 samples
  Calibration progress: 100/374 samples
  Calibration progress: 150/374 samples
  Calibration progress: 200/374 samples
  Calibration progress: 250/374 samples
  Calibration progress: 300/374 samples
  Calibration progress: 350/374 samples
  Calibration complete: 374 samples processed

Quantization Summary:
model.layers.0.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.3750 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.0.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7461 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.3750 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.0.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6992 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.3750 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.0.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0610 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5117 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.0.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4629 calibrator=MaxCalibrator quant)
model.layers.0.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.0.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.0.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.0.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.7500 calibrator=MaxCalibrator quant)
model.layers.0.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.0.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5977 calibrator=MaxCalibrator quant)
model.layers.0.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.7500 calibrator=MaxCalibrator quant)
model.layers.0.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.0.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1963 calibrator=MaxCalibrator quant)
model.layers.0.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.2500 calibrator=MaxCalibrator quant)
model.layers.0.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.0.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6133 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.6562 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.1.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5352 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.6562 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.1.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3555 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.6562 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.1.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0967 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6211 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.1.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4141 calibrator=MaxCalibrator quant)
model.layers.1.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.1.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.1.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.1.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.3750 calibrator=MaxCalibrator quant)
model.layers.1.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.1.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5273 calibrator=MaxCalibrator quant)
model.layers.1.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.3750 calibrator=MaxCalibrator quant)
model.layers.1.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.1.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4629 calibrator=MaxCalibrator quant)
model.layers.1.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=478.0000 calibrator=MaxCalibrator quant)
model.layers.1.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.1.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7070 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.1875 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.2.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2617 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.1875 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.2.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3496 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.1875 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.2.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0586 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=1.5156 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.2.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3457 calibrator=MaxCalibrator quant)
model.layers.2.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.2.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.2.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.2.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=5.7188 calibrator=MaxCalibrator quant)
model.layers.2.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.2.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3242 calibrator=MaxCalibrator quant)
model.layers.2.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=5.7188 calibrator=MaxCalibrator quant)
model.layers.2.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.2.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2480 calibrator=MaxCalibrator quant)
model.layers.2.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.3906 calibrator=MaxCalibrator quant)
model.layers.2.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.2.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6055 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.2500 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.3.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2188 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.2500 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.3.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2832 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.2500 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.3.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1357 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=1.3984 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.3.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3770 calibrator=MaxCalibrator quant)
model.layers.3.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.3.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.3.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.3.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.7812 calibrator=MaxCalibrator quant)
model.layers.3.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.3.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5078 calibrator=MaxCalibrator quant)
model.layers.3.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.7812 calibrator=MaxCalibrator quant)
model.layers.3.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.3.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2754 calibrator=MaxCalibrator quant)
model.layers.3.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.9062 calibrator=MaxCalibrator quant)
model.layers.3.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.3.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5469 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.1875 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.4.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3301 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.1875 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.4.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3359 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.1875 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.4.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0742 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=1.5391 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.4.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3574 calibrator=MaxCalibrator quant)
model.layers.4.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.4.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.4.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.4.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.5000 calibrator=MaxCalibrator quant)
model.layers.4.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.4.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3926 calibrator=MaxCalibrator quant)
model.layers.4.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.5000 calibrator=MaxCalibrator quant)
model.layers.4.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.4.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3047 calibrator=MaxCalibrator quant)
model.layers.4.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.6875 calibrator=MaxCalibrator quant)
model.layers.4.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.4.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6562 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=11.2500 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.5.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2578 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=11.2500 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.5.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5273 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=11.2500 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.5.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1357 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.0156 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.5.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3477 calibrator=MaxCalibrator quant)
model.layers.5.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.5.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.5.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.5.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.9375 calibrator=MaxCalibrator quant)
model.layers.5.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.5.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4180 calibrator=MaxCalibrator quant)
model.layers.5.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.9375 calibrator=MaxCalibrator quant)
model.layers.5.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.5.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4277 calibrator=MaxCalibrator quant)
model.layers.5.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.5312 calibrator=MaxCalibrator quant)
model.layers.5.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.5.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6016 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.6250 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.6.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2734 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.6250 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.6.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2871 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.6250 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.6.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0596 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=1.9844 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.6.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6953 calibrator=MaxCalibrator quant)
model.layers.6.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.6.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.6.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.6.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.0000 calibrator=MaxCalibrator quant)
model.layers.6.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.6.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4668 calibrator=MaxCalibrator quant)
model.layers.6.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.0000 calibrator=MaxCalibrator quant)
model.layers.6.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.6.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3008 calibrator=MaxCalibrator quant)
model.layers.6.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.9062 calibrator=MaxCalibrator quant)
model.layers.6.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.6.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6602 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.3750 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.7.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2539 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.3750 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.7.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2676 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.3750 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.7.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0781 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.1875 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.7.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3184 calibrator=MaxCalibrator quant)
model.layers.7.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.7.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.7.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.7.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.5625 calibrator=MaxCalibrator quant)
model.layers.7.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.7.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4102 calibrator=MaxCalibrator quant)
model.layers.7.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.5625 calibrator=MaxCalibrator quant)
model.layers.7.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.7.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2871 calibrator=MaxCalibrator quant)
model.layers.7.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.2500 calibrator=MaxCalibrator quant)
model.layers.7.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.7.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6406 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=15.5000 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.8.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4531 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=15.5000 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.8.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4551 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=15.5000 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.8.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0854 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.2969 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.8.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3926 calibrator=MaxCalibrator quant)
model.layers.8.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.8.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.8.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.8.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.7500 calibrator=MaxCalibrator quant)
model.layers.8.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.8.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3262 calibrator=MaxCalibrator quant)
model.layers.8.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.7500 calibrator=MaxCalibrator quant)
model.layers.8.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.8.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2930 calibrator=MaxCalibrator quant)
model.layers.8.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.7500 calibrator=MaxCalibrator quant)
model.layers.8.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.8.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7344 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.q_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.2500 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.q_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.9.self_attn.q_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2490 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.k_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.2500 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.k_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.9.self_attn.k_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3691 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.v_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.2500 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.v_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.9.self_attn.v_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0977 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.o_proj.input_quantizer                                  TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.0000 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.o_proj.output_quantizer                                 TensorQuantizer(disabled)
model.layers.9.self_attn.o_proj.weight_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3574 calibrator=MaxCalibrator quant)
model.layers.9.self_attn.q_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.9.self_attn.k_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.9.self_attn.v_bmm_quantizer                                         TensorQuantizer(disabled)
model.layers.9.mlp.gate_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.8125 calibrator=MaxCalibrator quant)
model.layers.9.mlp.gate_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.9.mlp.gate_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4805 calibrator=MaxCalibrator quant)
model.layers.9.mlp.up_proj.input_quantizer                                       TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.8125 calibrator=MaxCalibrator quant)
model.layers.9.mlp.up_proj.output_quantizer                                      TensorQuantizer(disabled)
model.layers.9.mlp.up_proj.weight_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3047 calibrator=MaxCalibrator quant)
model.layers.9.mlp.down_proj.input_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.9688 calibrator=MaxCalibrator quant)
model.layers.9.mlp.down_proj.output_quantizer                                    TensorQuantizer(disabled)
model.layers.9.mlp.down_proj.weight_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7070 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.8750 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.10.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3789 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.8750 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.10.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4375 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.8750 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.10.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0645 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.1094 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.10.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5156 calibrator=MaxCalibrator quant)
model.layers.10.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.10.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.10.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.10.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.5000 calibrator=MaxCalibrator quant)
model.layers.10.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.10.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3457 calibrator=MaxCalibrator quant)
model.layers.10.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.5000 calibrator=MaxCalibrator quant)
model.layers.10.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.10.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2461 calibrator=MaxCalibrator quant)
model.layers.10.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=7.3750 calibrator=MaxCalibrator quant)
model.layers.10.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.10.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7070 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.8750 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.11.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2021 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.8750 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.11.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3125 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.8750 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.11.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0723 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.6875 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.11.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2773 calibrator=MaxCalibrator quant)
model.layers.11.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.11.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.11.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.11.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.1875 calibrator=MaxCalibrator quant)
model.layers.11.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.11.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3867 calibrator=MaxCalibrator quant)
model.layers.11.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.1875 calibrator=MaxCalibrator quant)
model.layers.11.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.11.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2314 calibrator=MaxCalibrator quant)
model.layers.11.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=6.4688 calibrator=MaxCalibrator quant)
model.layers.11.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.11.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5938 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.7500 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.12.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2520 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.7500 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.12.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2305 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.7500 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.12.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0977 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.2656 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.12.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4590 calibrator=MaxCalibrator quant)
model.layers.12.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.12.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.12.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.12.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.9375 calibrator=MaxCalibrator quant)
model.layers.12.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.12.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4258 calibrator=MaxCalibrator quant)
model.layers.12.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.9375 calibrator=MaxCalibrator quant)
model.layers.12.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.12.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3281 calibrator=MaxCalibrator quant)
model.layers.12.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=7.6562 calibrator=MaxCalibrator quant)
model.layers.12.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.12.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.9141 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.1250 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.13.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1777 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.1250 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.13.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3926 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.1250 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.13.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0996 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.4844 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.13.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7773 calibrator=MaxCalibrator quant)
model.layers.13.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.13.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.13.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.13.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.5000 calibrator=MaxCalibrator quant)
model.layers.13.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.13.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4844 calibrator=MaxCalibrator quant)
model.layers.13.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.5000 calibrator=MaxCalibrator quant)
model.layers.13.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.13.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3652 calibrator=MaxCalibrator quant)
model.layers.13.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=7.0625 calibrator=MaxCalibrator quant)
model.layers.13.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.13.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.9102 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.0000 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.14.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3359 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.0000 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.14.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3730 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.0000 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.14.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0879 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.1562 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.14.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2207 calibrator=MaxCalibrator quant)
model.layers.14.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.14.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.14.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.14.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.7500 calibrator=MaxCalibrator quant)
model.layers.14.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.14.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4883 calibrator=MaxCalibrator quant)
model.layers.14.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.7500 calibrator=MaxCalibrator quant)
model.layers.14.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.14.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4570 calibrator=MaxCalibrator quant)
model.layers.14.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.3125 calibrator=MaxCalibrator quant)
model.layers.14.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.14.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.8203 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.3750 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.15.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4297 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.3750 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.15.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4004 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.3750 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.15.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1416 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.2344 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.15.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4668 calibrator=MaxCalibrator quant)
model.layers.15.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.15.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.15.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.15.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.9375 calibrator=MaxCalibrator quant)
model.layers.15.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.15.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3809 calibrator=MaxCalibrator quant)
model.layers.15.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.9375 calibrator=MaxCalibrator quant)
model.layers.15.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.15.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2812 calibrator=MaxCalibrator quant)
model.layers.15.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.0625 calibrator=MaxCalibrator quant)
model.layers.15.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.15.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6328 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.7500 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.16.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4023 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.7500 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.16.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3633 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.7500 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.16.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1367 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.1719 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.16.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4824 calibrator=MaxCalibrator quant)
model.layers.16.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.16.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.16.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.16.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.3125 calibrator=MaxCalibrator quant)
model.layers.16.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.16.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4863 calibrator=MaxCalibrator quant)
model.layers.16.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.3125 calibrator=MaxCalibrator quant)
model.layers.16.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.16.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2676 calibrator=MaxCalibrator quant)
model.layers.16.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.3750 calibrator=MaxCalibrator quant)
model.layers.16.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.16.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.8086 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.17.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2070 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.17.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3613 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.17.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0776 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.1250 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.17.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4688 calibrator=MaxCalibrator quant)
model.layers.17.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.17.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.17.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.17.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.2500 calibrator=MaxCalibrator quant)
model.layers.17.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.17.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3984 calibrator=MaxCalibrator quant)
model.layers.17.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.2500 calibrator=MaxCalibrator quant)
model.layers.17.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.17.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3164 calibrator=MaxCalibrator quant)
model.layers.17.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=14.9375 calibrator=MaxCalibrator quant)
model.layers.17.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.17.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6172 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.0000 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.18.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2139 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.0000 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.18.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2832 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=20.0000 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.18.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0869 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.8594 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.18.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.8281 calibrator=MaxCalibrator quant)
model.layers.18.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.18.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.18.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.18.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.7500 calibrator=MaxCalibrator quant)
model.layers.18.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.18.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5156 calibrator=MaxCalibrator quant)
model.layers.18.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.7500 calibrator=MaxCalibrator quant)
model.layers.18.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.18.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2363 calibrator=MaxCalibrator quant)
model.layers.18.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.6250 calibrator=MaxCalibrator quant)
model.layers.18.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.18.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7891 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.7500 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.19.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2656 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.7500 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.19.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3027 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.7500 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.19.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1025 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.2344 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.19.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5703 calibrator=MaxCalibrator quant)
model.layers.19.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.19.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.19.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.19.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.6250 calibrator=MaxCalibrator quant)
model.layers.19.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.19.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4688 calibrator=MaxCalibrator quant)
model.layers.19.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.6250 calibrator=MaxCalibrator quant)
model.layers.19.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.19.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2793 calibrator=MaxCalibrator quant)
model.layers.19.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.8750 calibrator=MaxCalibrator quant)
model.layers.19.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.19.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.8203 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.5000 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.20.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2402 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.5000 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.20.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3164 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.5000 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.20.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.0859 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=2.4688 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.20.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6094 calibrator=MaxCalibrator quant)
model.layers.20.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.20.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.20.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.20.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.8750 calibrator=MaxCalibrator quant)
model.layers.20.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.20.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4004 calibrator=MaxCalibrator quant)
model.layers.20.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=8.8750 calibrator=MaxCalibrator quant)
model.layers.20.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.20.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2852 calibrator=MaxCalibrator quant)
model.layers.20.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=26.8750 calibrator=MaxCalibrator quant)
model.layers.20.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.20.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4570 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.5000 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.21.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2246 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.5000 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.21.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3379 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.5000 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.21.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1240 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.2188 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.21.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2949 calibrator=MaxCalibrator quant)
model.layers.21.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.21.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.21.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.21.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.0000 calibrator=MaxCalibrator quant)
model.layers.21.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.21.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5469 calibrator=MaxCalibrator quant)
model.layers.21.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.0000 calibrator=MaxCalibrator quant)
model.layers.21.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.21.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5430 calibrator=MaxCalibrator quant)
model.layers.21.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=24.0000 calibrator=MaxCalibrator quant)
model.layers.21.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.21.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.8281 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.2500 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.22.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2285 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.2500 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.22.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3418 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=21.2500 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.22.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1074 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.7031 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.22.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3301 calibrator=MaxCalibrator quant)
model.layers.22.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.22.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.22.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.22.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.6875 calibrator=MaxCalibrator quant)
model.layers.22.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.22.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3965 calibrator=MaxCalibrator quant)
model.layers.22.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.6875 calibrator=MaxCalibrator quant)
model.layers.22.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.22.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1895 calibrator=MaxCalibrator quant)
model.layers.22.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=28.7500 calibrator=MaxCalibrator quant)
model.layers.22.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.22.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5898 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.7500 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.23.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2324 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.7500 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.23.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4707 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.7500 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.23.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1230 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.6875 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.23.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3867 calibrator=MaxCalibrator quant)
model.layers.23.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.23.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.23.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.23.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.7500 calibrator=MaxCalibrator quant)
model.layers.23.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.23.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4512 calibrator=MaxCalibrator quant)
model.layers.23.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.7500 calibrator=MaxCalibrator quant)
model.layers.23.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.23.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1953 calibrator=MaxCalibrator quant)
model.layers.23.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=31.3750 calibrator=MaxCalibrator quant)
model.layers.23.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.23.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6367 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.24.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2412 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.24.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3281 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.24.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1191 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.5000 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.24.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2988 calibrator=MaxCalibrator quant)
model.layers.24.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.24.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.24.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.24.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.8125 calibrator=MaxCalibrator quant)
model.layers.24.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.24.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5234 calibrator=MaxCalibrator quant)
model.layers.24.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.8125 calibrator=MaxCalibrator quant)
model.layers.24.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.24.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3535 calibrator=MaxCalibrator quant)
model.layers.24.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=43.7500 calibrator=MaxCalibrator quant)
model.layers.24.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.24.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5977 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=17.7500 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.25.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2314 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=17.7500 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.25.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4336 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=17.7500 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.25.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1348 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=3.9531 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.25.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3887 calibrator=MaxCalibrator quant)
model.layers.25.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.25.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.25.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.25.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.8125 calibrator=MaxCalibrator quant)
model.layers.25.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.25.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3672 calibrator=MaxCalibrator quant)
model.layers.25.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=9.8125 calibrator=MaxCalibrator quant)
model.layers.25.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.25.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2344 calibrator=MaxCalibrator quant)
model.layers.25.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=38.2500 calibrator=MaxCalibrator quant)
model.layers.25.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.25.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7070 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.0000 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.26.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2324 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.0000 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.26.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3535 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=19.0000 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.26.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1992 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.2812 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.26.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3398 calibrator=MaxCalibrator quant)
model.layers.26.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.26.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.26.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.26.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.0625 calibrator=MaxCalibrator quant)
model.layers.26.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.26.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4238 calibrator=MaxCalibrator quant)
model.layers.26.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.0625 calibrator=MaxCalibrator quant)
model.layers.26.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.26.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3320 calibrator=MaxCalibrator quant)
model.layers.26.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=40.5000 calibrator=MaxCalibrator quant)
model.layers.26.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.26.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6992 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.27.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2246 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.27.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4082 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.6250 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.27.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2578 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.0938 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.27.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4844 calibrator=MaxCalibrator quant)
model.layers.27.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.27.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.27.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.27.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.7500 calibrator=MaxCalibrator quant)
model.layers.27.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.27.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4121 calibrator=MaxCalibrator quant)
model.layers.27.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.7500 calibrator=MaxCalibrator quant)
model.layers.27.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.27.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2148 calibrator=MaxCalibrator quant)
model.layers.27.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=36.5000 calibrator=MaxCalibrator quant)
model.layers.27.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.27.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5312 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.0000 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.28.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2793 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.0000 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.28.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3008 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=18.0000 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.28.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.1699 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=4.9062 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.28.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6211 calibrator=MaxCalibrator quant)
model.layers.28.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.28.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.28.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.28.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.3125 calibrator=MaxCalibrator quant)
model.layers.28.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.28.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4902 calibrator=MaxCalibrator quant)
model.layers.28.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=10.3125 calibrator=MaxCalibrator quant)
model.layers.28.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.28.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3926 calibrator=MaxCalibrator quant)
model.layers.28.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=56.7500 calibrator=MaxCalibrator quant)
model.layers.28.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.28.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6680 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=14.6875 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.29.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3086 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=14.6875 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.29.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4004 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=14.6875 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.29.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2539 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=5.1250 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.29.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3535 calibrator=MaxCalibrator quant)
model.layers.29.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.29.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.29.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.29.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.6250 calibrator=MaxCalibrator quant)
model.layers.29.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.29.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4727 calibrator=MaxCalibrator quant)
model.layers.29.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=12.6250 calibrator=MaxCalibrator quant)
model.layers.29.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.29.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3867 calibrator=MaxCalibrator quant)
model.layers.29.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=44.2500 calibrator=MaxCalibrator quant)
model.layers.29.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.29.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7344 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.8750 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.30.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2637 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.8750 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.30.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3594 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=16.8750 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.30.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2070 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=5.2500 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.30.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.2832 calibrator=MaxCalibrator quant)
model.layers.30.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.30.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.30.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.30.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=14.1875 calibrator=MaxCalibrator quant)
model.layers.30.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.30.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5859 calibrator=MaxCalibrator quant)
model.layers.30.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=14.1875 calibrator=MaxCalibrator quant)
model.layers.30.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.30.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3867 calibrator=MaxCalibrator quant)
model.layers.30.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=41.0000 calibrator=MaxCalibrator quant)
model.layers.30.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.30.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4336 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.q_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=11.1250 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.q_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.31.self_attn.q_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4199 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.k_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=11.1250 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.k_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.31.self_attn.k_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5703 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.v_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=11.1250 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.v_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.31.self_attn.v_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.3125 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.o_proj.input_quantizer                                 TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=7.9062 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.o_proj.output_quantizer                                TensorQuantizer(disabled)
model.layers.31.self_attn.o_proj.weight_quantizer                                TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.4375 calibrator=MaxCalibrator quant)
model.layers.31.self_attn.q_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.31.self_attn.k_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.31.self_attn.v_bmm_quantizer                                        TensorQuantizer(disabled)
model.layers.31.mlp.gate_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=15.0625 calibrator=MaxCalibrator quant)
model.layers.31.mlp.gate_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.31.mlp.gate_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.7695 calibrator=MaxCalibrator quant)
model.layers.31.mlp.up_proj.input_quantizer                                      TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=15.0625 calibrator=MaxCalibrator quant)
model.layers.31.mlp.up_proj.output_quantizer                                     TensorQuantizer(disabled)
model.layers.31.mlp.up_proj.weight_quantizer                                     TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.6719 calibrator=MaxCalibrator quant)
model.layers.31.mlp.down_proj.input_quantizer                                    TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=202.0000 calibrator=MaxCalibrator quant)
model.layers.31.mlp.down_proj.output_quantizer                                   TensorQuantizer(disabled)
model.layers.31.mlp.down_proj.weight_quantizer                                   TensorQuantizer((2, 1) bit fake block_sizes={-1: 16, 'type': 'dynamic', 'scale_bits': (4, 3)}, amax=0.5469 calibrator=MaxCalibrator quant)
lm_head.input_quantizer                                                          TensorQuantizer(disabled)
lm_head.output_quantizer                                                         TensorQuantizer(disabled)
lm_head.weight_quantizer                                                         TensorQuantizer(disabled)
771 TensorQuantizers found in model

======================================================================
Exporting NVFP4 checkpoint...
======================================================================

`torch_dtype` is deprecated! Use `dtype` instead!

Verifying output checkpoint...
  âœ“ config.json
  âœ“ hf_quant_config.json
  âœ“ Model weights: 2 files, 6.03 GB

======================================================================
NVFP4 quantization complete!
======================================================================

Output saved to: /media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4

To use with vLLM:
  llm = LLM(model="/media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4", quantization="modelopt")

To serve with vLLM:
  vllm serve /media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4 --quantization modelopt
======================================================================

[?2004h(venv) phaedawg@d011sd01:~/nvidia-opt/PhaeDawg-QuantScripts_Compressed-Tensors/Nvidia-Model_OPT$ du -sh /media/fmo[?5h[?5ldels/TheHouseOfTheDude/Ll[?5h[?5lama-3.1-8B-Instruct_ModelOpt/NVFP4/
[?2004l5.7G[4C/media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4/
[?2004h(venv) phaedawg@d011sd01:~/nvidia-opt/PhaeDawg-QuantScripts_Compressed-Tensors/Nvidia-Model_OPT$ ls -lah [7m/media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4[27m/media/fmodels/TheHouseOfTheDude/Llama-3.1-8B-Instruct_ModelOpt/NVFP4
[?2004ltotal 5.7G
drwxrwsr-x 2 phaedawg aimodels  4.0K Feb  1 14:51 [1m[34m.[0m
drwxrwsr-x 3 phaedawg aimodels  4.0K Feb  1 14:46 [1m[34m..[0m
-rw-rw-r-- 1 phaedawg aimodels  4.6K Feb  1 14:51 chat_template.jinja
-rw-rw-r-- 1 phaedawg aimodels  1.8K Feb  1 14:51 config.json
-rw-rw-r-- 1 phaedawg aimodels   184 Feb  1 14:51 generation_config.json
-rw-rw-r-- 1 phaedawg aimodels   267 Feb  1 14:51 hf_quant_config.json
-rw-rw-r-- 1 phaedawg aimodels  4.7G Feb  1 14:51 model-00001-of-00002.safetensors
-rw-rw-r-- 1 phaedawg aimodels 1003M Feb  1 14:51 model-00002-of-00002.safetensors
-rw-rw-r-- 1 phaedawg aimodels   81K Feb  1 14:51 model.safetensors.index.json
-rw-rw-r-- 1 phaedawg aimodels   325 Feb  1 14:51 special_tokens_map.json
-rw-rw-r-- 1 phaedawg aimodels   50K Feb  1 14:51 tokenizer_config.json
-rw-rw-r-- 1 phaedawg aimodels   17M Feb  1 14:51 tokenizer.json
[?2004h(venv) phaedawg@d011sd01:~/nvidia-opt/PhaeDawg-QuantScripts_Compressed-Tensors/Nvidia-Model_OPT$ rm -rf du -sh /media/fmodels/meta-llama/Llama-3.1-8B-Instruct/[P[P[P[P[P[P[P[?5h[?5l
[?2004l30G[5C/media/fmodels/meta-llama/Llama-3.1-8B-Instruct/